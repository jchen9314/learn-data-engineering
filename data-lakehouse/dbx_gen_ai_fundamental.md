# Generative AI Fundamental

## Introducing Generative AI

### Generative AI Basics

- AI: a multidisciplinary field of CS that aims to create systems capable of emulating and surpassing human-level intelligence
- ML: learn from existing data and make predictions without being explicitly programmed
- DL: use "artificial neural network" to learn from data
- Gen AI: sub-field of AI that focuses on **generating** new content such as image, text, audio, video, code, 3d objects, synthetic data

#### Factors making Gen AI possible now

- Large datasets:
  - availability of large and diverse datasets
  - AI models learn patterns, correlations, and characteristics of large datasets
  - pre-trained state-of-the-art models
- Computational power:
  - advancements in hardware; GPUs
  - access to cloud computing
  - open-source software, hugging face
- Innovative DL models
  - Generative Adversarial networks (GANs)
  - Transformers architecture
  - Reinforcement learning from human feedback (RLHF)

### LLMs and Generative AI

- LLM (large language model)
  - model trained on massive datasets to achieve advanced language processing capabilities; Based on DL neural networks
  - structure:
    - encoder
    - transformer
    - decoder
  - Common LLM tasks

| Task                              	| Description                                                                                                                                            |
|:-----------------------------------	|:-----------------------------------------------------------------------------------------------------------------------------------------------------------|
| Content creation and augmentation 	| Generating coherent and contextually relevant text. LLMs excel at tasks like text completion, creative writing, story generation, and dialogue generation. |
| Summarization                     	| Summarizing long documents or articles into concise summaries. LLMs provide an efficient way to extract key info from large volume of text.                |
| Question answering                	| Comprehend questions and provide relevant answers by extracting info from their pre-trained knowledge.                                                     |
| Machine translation               	| Auto converting a text from one language to another. LLMs can explain language structure like grammatical rules                                            |
| Classification                    	| Categorizing text into predefined classes or topics. LLLs are useful for tasks like topic classification, spam detection, or sentiment analysis            |
| Named Entity Recognition          	| Identifying and extracting named entities like names of persons, organizations, locations, dates, and more from text                                       |
| Tone/level of content             	| Adjusting the text's tone (professional, humorous, etc.) or complexity level (eg. fourth-grade level)                                                      |
| Code generation                   	| Generating code in a specified programming language or converting code from one language to another                                                        |

- Foundation model (GPT-4, BART, MPT-7B etc.): large ML model trained on vast amount of data and fine-tuned for more specific language understanding and generation tasks

## Finding Success with Generative AI

### LLM Applications

### Generative AI with Databricks ML

### AI Adoption Preparation

## Assessing Potential Risks and Challenges

### Legality

### Ethical Considerations

### Human-AI Interaction

